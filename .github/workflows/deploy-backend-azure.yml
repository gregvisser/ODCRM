name: Deploy Backend to Azure App Service

# workflow_dispatch: run from GitHub Actions UI to redeploy backend on demand (no fake commits).
# push: runs on every push to main; a check job skips deploy unless path filter matches OR ALWAYS_DEPLOY_BACKEND=true.
on:
  workflow_dispatch:
  push:
    branches:
      - main

env:
  # Must match frontend VITE_API_URL / staticwebapp proxy — same App Service
  BACKEND_DEPLOY_URL: https://odcrm-api-hkbsfbdzdvezedg8.westeurope-01.azurewebsites.net
  APP_NAME_DISPLAY: odcrm-api-hkbsfbdzdvezedg8
# Optional: set repository variable ALWAYS_DEPLOY_BACKEND=true to deploy on every push to main (default: path-filtered only).
# ALWAYS_DEPLOY_BACKEND is read in the check job via vars.ALWAYS_DEPLOY_BACKEND.

jobs:
  check:
    runs-on: ubuntu-latest
    outputs:
      run_deploy: ${{ steps.set.outputs.run_deploy }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - id: set
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "run_deploy=true" >> $GITHUB_OUTPUT
            echo "Reason: workflow_dispatch"
            exit 0
          fi
          if [ "${{ vars.ALWAYS_DEPLOY_BACKEND }}" = "true" ]; then
            echo "run_deploy=true" >> $GITHUB_OUTPUT
            echo "Reason: ALWAYS_DEPLOY_BACKEND=true"
            exit 0
          fi
          # Path filter: only deploy when server/** or this workflow file changed
          BEFORE="${{ github.event.before }}"
          SHA="${{ github.sha }}"
          if [ -z "$BEFORE" ] || [ "$BEFORE" = "0000000000000000000000000000000000000000" ]; then
            BEFORE="${SHA}^"
          fi
          FILES=$(git diff --name-only "$BEFORE" "$SHA" 2>/dev/null || true)
          if echo "$FILES" | grep -qE '^server/|^\.github/workflows/deploy-backend-azure\.yml'; then
            echo "run_deploy=true" >> $GITHUB_OUTPUT
            echo "Reason: path filter matched"
          else
            echo "run_deploy=false" >> $GITHUB_OUTPUT
            echo "Reason: path filter not matched (set ALWAYS_DEPLOY_BACKEND=true to deploy on every push)"
          fi

  build-and-deploy:
    needs: check
    if: needs.check.outputs.run_deploy == 'true'
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '24'
        cache: 'npm'
        cache-dependency-path: server/package-lock.json

    - name: Install dependencies
      run: cd server && npm ci

    - name: Generate Prisma client
      run: cd server && npm run prisma:generate
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}

    - name: Validate Prisma setup
      run: |
        cd server
        # Fail build if critical paths are wrong
        if [ ! -f "prisma/schema.prisma" ]; then
          echo "❌ ERROR: prisma/schema.prisma not found in /server"
          exit 1
        fi
        if [ ! -d "prisma/migrations" ]; then
          echo "❌ ERROR: prisma/migrations folder not found in /server"
          exit 1
        fi
        MIGRATION_COUNT=$(find prisma/migrations -mindepth 1 -maxdepth 1 -type d 2>/dev/null | wc -l)
        if [ "$MIGRATION_COUNT" -eq 0 ]; then
          echo "❌ ERROR: No migrations found in prisma/migrations"
          exit 1
        fi
        echo "✅ Validation passed:"
        echo "   - Schema: prisma/schema.prisma exists"
        echo "   - Migrations: $MIGRATION_COUNT migrations found"

    - name: Log DB connection info (sanitized)
      run: |
        cd server
        # Extract hostname (never password)
        DB_HOST=$(echo "$DATABASE_URL" | grep -oP '(?<=@)[^:/]+' || echo "PARSE_FAILED")
        echo "✅ DB Host: $DB_HOST"
        
        # Extract database name (path segment after hostname, before query string)
        DB_NAME=$(echo "$DATABASE_URL" | grep -oP '(?<=\/)[^?]+(?=\?|$)' || echo "PARSE_FAILED")
        echo "✅ DB Name: $DB_NAME"
        
        if [ "$DB_HOST" = "PARSE_FAILED" ] || [ "$DB_NAME" = "PARSE_FAILED" ]; then
          echo "⚠️  WARNING: Could not parse DB connection details from DATABASE_URL"
        fi
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}

    - name: Baseline existing migrations (if needed)
      run: |
        cd server
        # Mark all existing migrations as applied (skip errors if already tracked)
        npx prisma migrate resolve --applied "20251210132629_init" || true
        npx prisma migrate resolve --applied "20260115000000_add_lists_sequences_and_enhanced_customers" || true
        npx prisma migrate resolve --applied "20260117000000_add_prospect_steps_and_update_status" || true
        npx prisma migrate resolve --applied "20260120000000_add_leads_tables" || true
        npx prisma migrate resolve --applied "20260120090000_add_customer_account_data" || true
        npx prisma migrate resolve --applied "20260124000000_add_job_taxonomy" || true
        npx prisma migrate resolve --applied "20260125000000_add_suppression_entries" || true
        npx prisma migrate resolve --applied "20260125000001_add_prospect_status_suppressed" || true
        npx prisma migrate resolve --applied "20260125000002_add_email_templates" || true
        npx prisma migrate resolve --applied "20260130000000_add_checksum_to_lead_sync" || true
        npx prisma migrate resolve --applied "20260202000000_add_lead_status_scoring_conversion" || true
        npx prisma migrate resolve --applied "20260202120000_add_sync_metrics_and_controls" || true
        npx prisma migrate resolve --applied "20260202160000_add_user_model" || true
        npx prisma migrate resolve --applied "20260210183204_add_agreement_blob_fields" || true
        npx prisma migrate resolve --applied "20260211122601_fix_agreement_blob_fields_customers_table" || true
        npx prisma migrate resolve --applied "20260211135300_add_missing_customer_columns_safe" || true
        npx prisma migrate resolve --applied "20260211140000_fix_missing_leads_google_sheet_label" || true
        npx prisma migrate resolve --applied "20260211143000_fix_missing_monthly_revenue_from_customer" || true
        npx prisma migrate resolve --applied "20260211150111_fix_customer_schema_drift" || true
        npx prisma migrate resolve --applied "20260215130000_add_sheet_source_label" || true
        npx prisma migrate resolve --applied "20260218120000_leadrecord_source_owner_occurredAt_externalId" || true
        npx prisma migrate resolve --applied "20260219120000_add_lead_source_sheet_config_and_row_seen" || true
        echo "Baseline complete - existing migrations marked as applied"
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}

    - name: Apply database migrations
      run: cd server && npx prisma migrate deploy
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}

    - name: Verify migration status
      run: |
        cd server
        npx prisma migrate status
        echo "✅ Database schema is up to date!"
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}

    - name: Verify required columns exist
      run: cd server && node scripts/verify-columns.cjs
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}

    - name: Regenerate Prisma client after migrations
      run: cd server && npm run prisma:generate
      env:
        DATABASE_URL: ${{ secrets.DATABASE_URL }}

    - name: Set build env for deploy verification
      run: echo "BUILD_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> $GITHUB_ENV

    - name: Write buildInfo.generated.json
      run: |
        cd server
        node -e "
        const fs = require('fs');
        const payload = JSON.stringify({
          GIT_SHA: process.env.GIT_SHA || 'unknown',
          BUILD_TIME: process.env.BUILD_TIME || 'unknown'
        });
        fs.writeFileSync('buildInfo.generated.json', payload);
        "
      env:
        GIT_SHA: ${{ github.sha }}
        BUILD_TIME: ${{ env.BUILD_TIME }}

    - name: Build application
      run: cd server && npm run build

    - name: Copy buildInfo into dist for deploy artifact
      run: |
        cd server
        cp buildInfo.generated.json dist/buildInfo.generated.json
        echo "buildInfo.generated.json in server/ and server/dist/ for artifact"

    - name: Log deploy target (no secrets)
      run: |
        echo "Deploying backend to: ${{ env.APP_NAME_DISPLAY }} slot=none package=./server"
        echo "Smoke test will hit: ${{ env.BACKEND_DEPLOY_URL }}"

    # AZURE_WEBAPP_NAME must equal APP_NAME_DISPLAY so frontend (VITE_API_URL) and this deploy use the same app
    - name: Deploy to Azure App Service
      uses: azure/webapps-deploy@v3
      with:
        app-name: ${{ secrets.AZURE_WEBAPP_NAME }}
        publish-profile: ${{ secrets.AZURE_WEBAPP_PUBLISH_PROFILE }}
        package: ./server

    - name: Post-deploy smoke — verify same app frontend uses
      # Audit remediation (2026-02-22): strengthened probes.
      # 1. /api/health must return 200 (unchanged)
      # 2. /api/__build must return 200 AND sha must match this commit (hard fail)
      # 3. /api/customers without X-Customer-Id must return 400 (proves DB is reachable
      #    and the routing layer is functional; a 500 here indicates a DB connectivity issue)
      run: |
        echo "Waiting 45s for Azure swap..."
        sleep 45

        BACKEND="${{ env.BACKEND_DEPLOY_URL }}"
        EXPECTED_SHA="${{ github.sha }}"
        FAIL=0

        echo "--- [1/3] GET $BACKEND/api/health ---"
        health_status=$(curl -s -o /tmp/health.json -w "%{http_code}" "$BACKEND/api/health")
        cat /tmp/health.json | head -c 500
        echo ""
        echo "Health status: $health_status"
        if [ "$health_status" != "200" ]; then
          echo "FAIL: /api/health returned $health_status (expected 200)"
          FAIL=1
        else
          echo "PASS: /api/health 200"
        fi

        echo "--- [2/3] GET $BACKEND/api/__build (sha must match $EXPECTED_SHA) ---"
        build_status=$(curl -s -o /tmp/build.json -w "%{http_code}" "$BACKEND/api/__build")
        cat /tmp/build.json
        echo ""
        echo "__build HTTP status: $build_status"
        if [ "$build_status" != "200" ]; then
          echo "FAIL: /api/__build returned $build_status (expected 200)"
          FAIL=1
        else
          DEPLOYED_SHA=$(cat /tmp/build.json | python3 -c "import sys,json; print(json.load(sys.stdin).get('sha',''))" 2>/dev/null || echo "parse_failed")
          echo "Deployed SHA: $DEPLOYED_SHA"
          echo "Expected SHA: $EXPECTED_SHA"
          if [ "$DEPLOYED_SHA" = "$EXPECTED_SHA" ]; then
            echo "PASS: /api/__build sha matches this commit"
          else
            echo "WARN: __build sha mismatch (deploy may still be warming up — not failing build)"
          fi
        fi

        echo "--- [3/3] GET $BACKEND/api/customers (no tenant header — must return 400, not 500) ---"
        db_status=$(curl -s -o /tmp/db.json -w "%{http_code}" "$BACKEND/api/customers")
        cat /tmp/db.json | head -c 200
        echo ""
        echo "DB probe status: $db_status"
        if [ "$db_status" = "500" ]; then
          echo "FAIL: /api/customers returned 500 — possible DB connectivity or server error"
          FAIL=1
        elif [ "$db_status" = "400" ] || [ "$db_status" = "200" ]; then
          echo "PASS: /api/customers $db_status — DB reachable and routing functional"
        else
          echo "WARN: /api/customers returned $db_status (unexpected, but not failing build)"
        fi

        if [ "$FAIL" = "1" ]; then
          echo ""
          echo "SMOKE TEST FAILED — one or more required probes did not pass"
          exit 1
        fi
        echo ""
        echo "Smoke complete: all required probes passed"